{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import rasterio\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_origin\n",
    "import fiona\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from rasterio import features\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon, MultiPolygon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.path.abspath('')\n",
    "\n",
    "# Search for the 'constants.py' file starting from the current directory and moving up the hierarchy\n",
    "project_root = current_dir\n",
    "while not os.path.isfile(os.path.join(project_root, 'constants.py')):\n",
    "    project_root = os.path.dirname(project_root)\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import STUDY_BOUNDARY_PATH, OUTPUT_PATH, LUP_YEAR,ROAD_PATH , RIVER_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/romero61/../../capstone/pyforest/ml_data/features/dissolved_road/dissolved_road.gpkg']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROAD_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "study_boundary = gpd.read_file(STUDY_BOUNDARY_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the desired resolution and extent for your output rasters to match the tree cover and deforestation rasters.\n",
    " reproject the study_boundary to match the output CRS and update its total bounds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_crs = 'EPSG:4326'\n",
    "output_extent = (-62.64186038139295, -25.354320073574613, -57.14929123970096, -19.287457970745013)\n",
    "output_resolution = (0.00026949458523585647, -0.00026949458523585647)\n",
    "study_boundary = study_boundary.to_crs(output_crs)\n",
    "study_area_bounds = study_boundary.total_bounds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector to Raster \n",
    "This function reads an input vector file (GeoPackage or Shapefile), converts the attribute column to numerical values or sets it to a single value if provided, and prepares the metadata for creating an output raster file.\n",
    "\n",
    "input_vector: The path to the input vector file (GeoPackage or Shapefile).\n",
    "\n",
    "output_raster: The path to the output raster file.\n",
    "\n",
    "attribute: The name of the attribute column in the input vector file that should be used as the pixel value in the output raster.\n",
    "\n",
    "study_area_bounds: The bounds of the study area as a tuple (minx, miny, maxx, maxy).\n",
    "\n",
    "single_value (optional, default: None): If provided, all the features in the input vector will be encoded with this single value in the output raster. If not provided, the attribute column values will be used.\n",
    "\n",
    "resolution: output raster generated from the vector_to_raster function will match the resolution and extent of the Hansen dataset.\n",
    "\n",
    "dtype (optional, default: 'uint16'): The data type of the output raster pixel values.\n",
    "\n",
    "Replace NaN/null values and empty strings with 'Uncategorized'\n",
    "    #gdf[attribute] = gdf[attribute].apply(lambda x: \"Uncategorized\" if pd.isna(x) or x in [\"\", \"NA\", \"None\",'NULL','null','na'] else x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_to_raster(input_vector, output_raster, attribute, study_area_bounds, value_mapping, single_value=None, resolution=(abs(0.00026949458523585647), abs(-0.00026949458523585647)), dtype='uint16'):\n",
    "    # Check if input_vector is a GeoDataFrame or a file path\n",
    "    if isinstance(input_vector, gpd.GeoDataFrame):\n",
    "        gdf = input_vector\n",
    "    else:\n",
    "        # Read the input vector file (GeoPackage or Shapefile) into a GeoDataFrame\n",
    "        gdf = gpd.read_file(input_vector)\n",
    "    # Reproject the GeoDataFrame to the desired CRS (EPSG:4326)\n",
    "    gdf = gdf.to_crs(epsg=4326)\n",
    "\n",
    "    # Ensure that categorical column is string\n",
    "    gdf[attribute] = gdf[attribute].astype(str)\n",
    "   \n",
    "\n",
    "   # If single_value is None, convert the attribute column to numerical values\n",
    "    # If single_value is provided, set the attribute column to the provided single_value\n",
    "    if single_value is None:\n",
    "        gdf[attribute] = gdf[attribute].replace(value_mapping).astype(dtype)\n",
    "    else:\n",
    "        gdf[attribute] = single_value\n",
    "\n",
    "\n",
    "    # Use the study area bounds to define the dimensions and transform of the output raster\n",
    "    minx, miny, maxx, maxy = study_area_bounds\n",
    "    width = int(np.ceil((maxx - minx) / abs(resolution[0])))\n",
    "    height = int(np.ceil((maxy - miny) / abs(resolution[1])))\n",
    "    out_transform = rasterio.transform.from_bounds(minx, miny, maxx, maxy, width, height)\n",
    "\n",
    "\n",
    "    # Define the metadata for the output raster file\n",
    "    out_meta = {\n",
    "        'driver': 'GTiff',\n",
    "        'width': width,\n",
    "        'height': height,\n",
    "        'count': 1,\n",
    "        'dtype': dtype,\n",
    "        'crs': 'EPSG:4326',\n",
    "        'transform': out_transform\n",
    "    }\n",
    "    \n",
    "    # Open the output raster file for writing with the specified metadata\n",
    "    with rasterio.open(output_raster, 'w', **out_meta) as dst:\n",
    "        # Create a generator of tuples containing the geometry and attribute value for each feature in the input vector data\n",
    "        shapes = ((geom, value) for geom, value in zip(gdf['geometry'], gdf[attribute]))\n",
    "        \n",
    "        # Burn the geometries and their corresponding attribute values into a raster array\n",
    "        burned = features.rasterize(\n",
    "            shapes=shapes,         # The generator of geometry-attribute tuples\n",
    "            fill=0,                # The default value for pixels not covered by any geometry\n",
    "            out_shape=(height, width), # The shape of the output raster array (number of rows and columns)\n",
    "            transform=out_transform,   # The affine transformation matrix that maps pixel coordinates to the coordinate reference system\n",
    "            dtype=dtype            # The data type of the raster array\n",
    "        )\n",
    "        \n",
    "        # Write the burned raster array to the output raster file\n",
    "        dst.write(burned, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to call Vector to Raster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To write text file of value mapping\n",
    "def write_value_mapping(value_mapping, output_file):\n",
    "    with open(output_file, 'w') as f:\n",
    "        for key, value in value_mapping.items():\n",
    "            f.write(f'{key}: {value}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_columns(input_vector, output_dir, study_area_bounds, resolution, columns, value_mapping, single_value=None, file_name=None):\n",
    "    if file_name is None:\n",
    "        file_name = os.path.splitext(os.path.basename(input_vector))[0]\n",
    "\n",
    "    for column in columns:\n",
    "        column_output_dir = os.path.join(output_dir, column)\n",
    "        os.makedirs(column_output_dir, exist_ok=True)\n",
    "\n",
    "        output_raster = f\"{column_output_dir}/{file_name}_{column}_raster.tif\"\n",
    "        vector_to_raster(input_vector, output_raster, column, study_area_bounds, value_mapping[column], single_value=single_value, resolution=resolution)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Output Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where files will save, can add subfolders if desired\n",
    "output_dir = os.path.join(OUTPUT_PATH[0], 'processed_rasters')\n",
    "os.makedirs(output_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the function on a folder of shapefiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following uses the list of file paths defined in the constants.py folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files_from_list(file_list, output_dir, study_area_bounds, resolution, columns, single_value=None):\n",
    "    # Generate a global value mapping from the list of unique values for each column\n",
    "    global_value_mapping = {column: set() for column in columns}\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        gdf = gpd.read_file(file_path)\n",
    "        for column in columns:\n",
    "            global_value_mapping[column].update(gdf[column].astype(str).unique())\n",
    "    \n",
    "    for column in columns:\n",
    "        global_value_mapping[column] = {value: idx for idx, value in enumerate(sorted(list(global_value_mapping[column])), 1)}\n",
    "        print(f\"Global value mapping for {column}:\")\n",
    "        for value in global_value_mapping[column]:\n",
    "            print(f\"{value}: {global_value_mapping[column][value]}\")\n",
    "    \n",
    "    # Write the global value mapping for each column to separate .txt files in the corresponding column folder\n",
    "    for column in columns:\n",
    "        column_output_dir = os.path.join(output_dir, column)\n",
    "        os.makedirs(column_output_dir, exist_ok=True)\n",
    "\n",
    "        output_value_mapping_file = f\"{column_output_dir}/{column}_global_value_mapping.txt\"\n",
    "        write_value_mapping(global_value_mapping[column], output_value_mapping_file)\n",
    "\n",
    "    # Process each file with the global value mapping\n",
    "    for file_path in file_list:\n",
    "        file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        process_columns(file_path, output_dir, study_area_bounds, columns=columns, resolution=resolution, value_mapping=global_value_mapping, single_value=single_value, file_name=file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global value mapping for land_use_type:\n",
      "final_hedgerow: 1\n",
      "forest_reserve: 2\n",
      "paddocks: 3\n",
      "riparian_corridor: 4\n"
     ]
    }
   ],
   "source": [
    "process_files_from_list(LUP_YEAR, output_dir, study_area_bounds, output_resolution, columns=['land_use_type'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pyforest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aca51edb778be56207d5a76d5369999259e96b3950a8b6f86c3be07548c77925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
