Balanced Random Forest Classifier Model Report

# Summary 
The Balanced Random Forest Classifier performed reasonably well on this task, 
with an accuracy of  0.6631005487031116 and an F1-score of 0.6826224492796857. 
However, there is room for improvement, particularly in the precision and recall for class 1. 
Future work could explore different models, additional feature engineering, or further hyperparameter tuning to improve performance.

# Model Selection
We chose to use a Balanced Random Forest Classifier for this task. 
This model is an ensemble method that combines the predictions of several base estimators 
built with a given learning algorithm in order to improve generalizability and robustness over a single estimator. 
It also handles imbalanced classes, which is a common problem in many machine learning tasks.

Hyperparameter Tuning
We used RandomizedSearchCV for hyperparameter tuning. 
This method performs a random search on hyperparameters, which is more efficient than an exhaustive search like GridSearchCV.

The hyperparameters we tuned were:

'n_estimators': The number of trees in the forest.
'max_depth': The maximum depth of the tree.
'min_samples_split': The minimum number of samples required to split a node.
'min_samples_leaf': The minimum number of samples required at a leaf node.
'bootstrap': Whether bootstrap samples are used when building trees.

{'n_estimators': [40, 50, 60], 'max_depth': [150, 200, 250], 'min_samples_split': [4, 6, 8], 'min_samples_leaf': [1, 2, 3], 'bootstrap': [False]}

# Model Performance
The best parameters found by RandomizedSearchCV were:

Best parameters:, {'n_estimators': 40, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_depth': 200, 'bootstrap': False}



With these parameters, the model achieved the following performance metrics:
Best cross-validation score: 0.4806939132082945
Best model:, BalancedRandomForestClassifier(bootstrap=False, class_weight='balanced',
                               max_depth=200, min_samples_split=6,
                               n_estimators=40, random_state=42,
                               sampling_strategy='not majority')
Scorer function:, {'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'f1': make_scorer(f1_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True)}
Refit time (seconds): 312.6133728027344
Accuracy:, 0.6631005487031116
F1-score: 0.6826224492796857
# Testing Data
Classification report:
               precision    recall  f1-score   support

           0       0.84      0.68      0.75   6531816
           1       0.39      0.62      0.48   2202051

    accuracy                           0.66   8733867
   macro avg       0.62      0.65      0.62   8733867
weighted avg       0.73      0.66      0.68   8733867


#  TRAINING DATA Classificatin Report-Confusion Matrix

Training confusion matrix:
[[10330068  4910835]
 [ 1958726  3179394]]
Training classification report:
              precision    recall  f1-score   support

           0       0.84      0.68      0.75  15240903
           1       0.39      0.62      0.48   5138120

    accuracy                           0.66  20379023
   macro avg       0.62      0.65      0.62  20379023
weighted avg       0.73      0.66      0.68  20379023



This indicates that the model correctly classified [1,1] instances of class 0 and [2,2] instances of class 1, 
while misclassifying [1,2] instances of class 0 and [2,1] instances of class 1.

CV Results:
    mean_fit_time  std_fit_time  mean_score_time  std_score_time  ... split4_test_roc_auc mean_test_roc_auc std_test_roc_auc rank_test_roc_auc
0      355.627618     73.663608        22.131654        4.326158  ...            0.670456           0.67032         0.000313                 1
1      383.320939     68.126581        23.712256        4.194681  ...            0.670456           0.67032         0.000313                 1
2      402.401061     71.840189        23.817627        3.975432  ...            0.670456           0.67032         0.000313                 1
3      407.197038     75.895633        23.997709        4.234631  ...            0.670456           0.67032         0.000313                 1
4      355.880144     73.754487        22.162980        4.271512  ...            0.670456           0.67032         0.000313                 1
5      479.306129     92.668264        27.765102        4.950450  ...            0.670456           0.67032         0.000313                 1
6      369.005603      4.579910        23.805181        3.871782  ...            0.670456           0.67032         0.000313                 1
7      366.810801      3.670154        21.834719        0.141637  ...            0.670456           0.67032         0.000313                 1
8      363.504899      2.835245        21.921269        0.162113  ...            0.670456           0.67032         0.000313                 1
9      327.761504     39.402512        18.609106        0.171347  ...            0.670456           0.67032         0.000313                 1
10     486.080430     15.694839        21.153809        0.316424  ...            0.670456           0.67032         0.000313                 1
11     370.042160     15.076520        17.965962        0.236631  ...            0.670456           0.67032         0.000313                 1
12     360.244731      8.587591        20.559271        0.113326  ...            0.670456           0.67032         0.000313                 1
13     421.875533      0.857837        23.488540        0.121159  ...            0.670456           0.67032         0.000313                 1
14     424.109136     15.056875        22.904417        0.382595  ...            0.670456           0.67032         0.000313                 1

[15 rows x 42 columns]

