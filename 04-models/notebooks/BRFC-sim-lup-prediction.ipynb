{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (confusion_matrix, classification_report, accuracy_score, \n",
    "                             precision_score, recall_score, f1_score, roc_auc_score, \n",
    "                             precision_recall_curve, roc_curve, auc)\n",
    "from sklearn.model_selection import (train_test_split, cross_val_score,\n",
    "                                     GridSearchCV, RandomizedSearchCV)\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import joblib\n",
    "from joblib import dump\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=UserWarning)\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get the current working directory\n",
    "current_dir = os.path.abspath('')\n",
    "\n",
    "# Search for the 'constants.py' file starting from the current directory and moving up the hierarchy\n",
    "project_root = current_dir\n",
    "while not os.path.isfile(os.path.join(project_root, 'constants.py')):\n",
    "    project_root = os.path.dirname(project_root)\n",
    "\n",
    "# Add the project root to the Python path\n",
    "sys.path.append(project_root)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from constants import SERVER_PATH, OUTPUT_PATH, SIMULATION_FEATURES_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#output- update this for subsequent runs\n",
    "output_folder = os.path.join(OUTPUT_PATH[0], 'predictions-log')\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# helper function to read tiff files\n",
    "def read_tiff_image(file_path):\n",
    "    with rasterio.open(file_path) as src:\n",
    "        return src.read(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of paths to the raster files to be used as features\n",
    "feature_files = [os.path.join(SIMULATION_FEATURES_DIR[0], 'sim25_raster.tif')]\n",
    "#feature_files = [os.path.join(SIMULATION_FEATURES_DIR[0], 'sim50_raster.tif')]\n",
    "#feature_files = [os.path.join(SIMULATION_FEATURES_DIR[0], 'simhedges_raster.tif')]\n",
    "\n",
    "\n",
    "# Then you can use this list of feature_files to create feature_data_arrays and feature_data_flat:\n",
    "feature_data_arrays = [read_tiff_image(file_path) for file_path in feature_files]\n",
    "feature_data_flat = [data_array.flatten() for data_array in feature_data_arrays]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/romero61/../../capstone/pyforest/ml_data/output/sim_lup_features/sim25_raster.tif']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with rasterio.open(feature_files[0]) as src:\n",
    "    profile = src.profile\n",
    "    profile.update(dtype=rasterio.float32, count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'driver': 'GTiff', 'dtype': 'float32', 'nodata': -1.0, 'width': 20381, 'height': 22512, 'count': 1, 'crs': CRS.from_epsg(4326), 'transform': Affine(0.00026949458523585647, 0.0, -62.64186038139295,\n",
       "       0.0, -0.00026949458523585647, -19.287457970745013), 'tiled': False, 'interleave': 'band'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All raster data arrays have the same dimensions.\n",
      "Raster 0: (22512, 20381)\n"
     ]
    }
   ],
   "source": [
    "# Find the dimensions of all the raster data arrays\n",
    "raster_shapes = [raster_data.shape for raster_data in feature_data_arrays]\n",
    "\n",
    "# Check if all raster data arrays have the same dimensions\n",
    "if len(set(raster_shapes)) > 1:\n",
    "    print(\"There are mismatching dimensions:\")\n",
    "    for file_path, raster_shape in zip(raster_files, raster_shapes):\n",
    "        print(f\"File: {file_path}, Shape: {raster_shape}\")\n",
    "else:\n",
    "    print(\"All raster data arrays have the same dimensions.\")\n",
    "    # Check the dimensions of all the raster data arrays\n",
    "    for i, data_array in enumerate(feature_data_arrays):\n",
    "        print(f\"Raster {i}: {data_array.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack and Flatten Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# NoData Value\n",
    "no_data_value = -1\n",
    "\n",
    "# Stack the flattened raster data\n",
    "X_flat = np.column_stack(feature_data_flat)\n",
    "\n",
    "# Remove rows with NoData values\n",
    "valid_rows_X = ~(X_flat == no_data_value).any(axis=1)\n",
    "\n",
    "# Create a new array X_cleaned by selecting only the rows in X_flat that correspond to the True elements in valid_rows_X\n",
    "X_cleaned = X_flat[valid_rows_X]\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure your data cleaning steps have been applied correctly, you can check the following:\n",
    "\n",
    "**NoData values have been removed:** You should confirm that there are no NoData values in your cleaned data. This can be done by asserting that there are no occurrences of no_data_value in X_cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "assert not (X_cleaned == no_data_value).any()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These assertions will throw an error if there is a NoData value in X_cleaned \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_cleaned: (109775603, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_cleaned:\", X_cleaned.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the model from the pickle file\n",
    "model = joblib.load('/Users/romero61/github/PYFOREST-ML/05-outputs/BRFC-features-log/best_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probabilities For Deforestation Predict on Simulated Land Use Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you use the predict_proba method of a classifier, it returns a 2D array where each row corresponds to a data point (in your case, a pixel), and each column corresponds to a class. The value in each cell is the probability that the given data point belongs to the given class, according to the model.\n",
    "\n",
    "In a binary classification problem, there are two classes: 0 and 1. Therefore, predict_proba returns a 2D array with two columns. The first column (index 0) contains the probabilities for class 0, and the second column (index 1) contains the probabilities for class 1.\n",
    "\n",
    "So, when you do probabilities[:, 1], you are selecting all rows (:) and the second column (1). This gives you a 1D array containing the probabilities that each data point belongs to class 1.\n",
    "\n",
    "In the context of the problem, class 1 might represent \"deforested\" areas. So class_1_probabilities would be an array where each value is the model's estimated probability that the corresponding pixel represents a deforested area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities on the new data for deforestation events\n",
    "probabilities = model.predict_proba(X_cleaned)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.30507248, 0.38903786, 0.49881947, 0.65758311])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten X_flat to a 1D array\n",
    "X_flat_1D = X_flat.flatten()\n",
    "\n",
    "# Create a flat array filled with NoData values\n",
    "probabilities_flat = np.full(X_flat_1D.shape[0], no_data_value, dtype=np.float32)\n",
    "\n",
    "# Replace the valid positions in the flat probabilities with the predicted probabilities\n",
    "probabilities_flat[valid_rows_X] = probabilities\n",
    "\n",
    "# Reshape the flat probabilities back into the shape of the original raster\n",
    "probabilities_reshaped = probabilities_flat.reshape(feature_data_arrays[0].shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = os.path.join(output_folder, \"sim-25-predicition.tiff\")\n",
    "\n",
    "# Save the reshaped predictions as a new raster file\n",
    "with rasterio.open(output_file, 'w', **profile) as dst:\n",
    "    dst.write(probabilities_reshaped, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.3 ('pyforest')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "aca51edb778be56207d5a76d5369999259e96b3950a8b6f86c3be07548c77925"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
