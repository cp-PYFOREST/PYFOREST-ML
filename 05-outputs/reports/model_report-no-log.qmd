---
title: “Model Metrics nolog”
author: “Guillermo Romero”
date: today
format:
  pdf:
      toc: false
      shift-heading-level-by: 2
      fig-pos: “H”
      fig-cap-location: top
      geometry:
        - top=1in
        - right=.8in
        - bottom=1in
        - left=.8in
      link-citations: yes
      linkcolor: blue
      include-in-header:
        text: |
          \usepackage{fancyhdr}
          \usepackage{titling}
          \pagestyle{fancy}
          \fancyhf{}
          \renewcommand\maketitle{
            \fancyhead[C]{
              \thetitle
              \ifx \theauthor\empty  \else \ – \theauthor \fi
              \ifx \thedate\empty  \else \ – \thedate \ \fi
            }
          }
          \fancyfoot[C]{\thepage}
editor:
  markdown:
    wrap: sentence
---

Balanced Random Forest Classifier Model Report

# Summary 

The Balanced Random Forest Classifier performed reasonably well on this task, 
with an accuracy of  0.9414494175375009 and an F1-score of 0.9422071764088368. 



# Model Selection

We chose to use a Balanced Random Forest Classifier for this task. 
This model is an ensemble method that combines the predictions of several base estimators 
built with a given learning algorithm in order to improve generalizability and robustness over a single estimator. 
It also handles imbalanced classes, which is a common problem in many machine learning tasks.

Hyperparameter Tuning
We used RandomizedSearchCV for hyperparameter tuning. 
This method performs a random search on hyperparameters, which is more efficient than an exhaustive search like GridSearchCV.

The hyperparameters we tuned were:

'n_estimators': The number of trees in the forest.
'max_depth': The maximum depth of the tree.
'min_samples_split': The minimum number of samples required to split a node.
'min_samples_leaf': The minimum number of samples required at a leaf node.
'bootstrap': Whether bootstrap samples are used when building trees.

{'n_estimators': [50, 100], 'max_depth': [None, 5, 10], 'min_samples_split': [2, 5], 'min_samples_leaf': [1, 2], 'max_features': ['sqrt']}

# Model Performance
The best parameters found by RandomizedSearchCV were:

Best parameters:, {'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': None}



With these parameters, the model achieved the following performance metrics:
Best cross-validation score: 0.884316378004154
Best model:, BalancedRandomForestClassifier(class_weight='balanced', min_samples_leaf=2,
                               random_state=42,
                               sampling_strategy='not majority')
Scorer function:, {'precision': make_scorer(precision_score, average=binary), 'recall': make_scorer(recall_score, average=binary), 'f1': make_scorer(f1_score, average=binary), 'roc_auc': make_scorer(roc_auc_score, needs_threshold=True)}
Refit time (seconds): 1041.5838499069214
Accuracy:, 0.9414494175375009
F1-score: 0.9422071764088368

# Testing Data

Classification report:

              precision    recall  f1-score   support

           0       0.97      0.95      0.96  19595447
           1       0.85      0.93      0.89   6606154

    accuracy                           0.94  26201601
   macro avg       0.91      0.94      0.92  26201601
weighted avg       0.94      0.94      0.94  26201601


#  TRAINING DATA Classificatin Report-Confusion Matrix

Training confusion matrix:

[[2103502   73770]
 [  14357  719660]]

Training classification report:

              precision    recall  f1-score   support

           0       0.99      0.97      0.98   2177272
           1       0.91      0.98      0.94    734017

    accuracy                           0.97   2911289
   macro avg       0.95      0.97      0.96   2911289
weighted avg       0.97      0.97      0.97   2911289



This indicates that the model correctly classified [1,1] instances of class 0 
and [2,2] instances of class 1, 

while misclassifying [1,2] instances of class 0 and [2,1] instances of class 1.

Area under Precision-Recall curve: 0.9428960242626893
Area under ROC curve: 0.9806840797614589

CV Results:
   mean_fit_time  std_fit_time  mean_score_time  ...  mean_test_roc_auc std_test_roc_auc rank_test_roc_auc
0     174.147246     25.162843         5.196244  ...           0.761401         0.000652                 7
1     255.070438     28.696970         7.657526  ...           0.843575         0.001075                 6
2     473.239252     16.994132        28.681204  ...           0.975005         0.000176                 3
3     273.170517      6.209141         7.851825  ...           0.843692         0.001103                 5
4     321.168215     23.863250         7.186115  ...           0.761123         0.000657                 8
5     330.275064     20.557780         7.089038  ...           0.761112         0.000643                 9
6     313.134226     28.804272         7.205827  ...           0.761104         0.000636                10
7     874.660524     30.777519        48.644971  ...           0.976328         0.000148                 2
8     375.489427      7.328228        10.719764  ...           0.844229         0.000784                 4
9     677.763613     52.431395        42.815766  ...           0.978974         0.000124                 1

[10 rows x 42 columns]

